import os
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS, Chroma

# === 1ï¸âƒ£ Load biáº¿n mÃ´i trÆ°á»ng ===
load_dotenv()

DATA_PATH = "data/project-text-semantic.csv"
VDB_DIR = os.getenv("VECTOR_DB_DIR", ".vector_store")
BACKEND = os.getenv("VECTOR_DB_BACKEND", "faiss").lower()
EMBED_MODEL = os.getenv("OPENAI_EMBED_MODEL", "text-embedding-3-small")

os.makedirs(VDB_DIR, exist_ok=True)

print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»«: {DATA_PATH}")
df = pd.read_csv(DATA_PATH)

# === 2ï¸âƒ£ Kiá»ƒm tra dá»¯ liá»‡u ===
if not {"id", "text"}.issubset(df.columns):
    raise ValueError("âŒ File CSV pháº£i cÃ³ 2 cá»™t: 'id' vÃ  'text'")

print(f"âœ… Sá»‘ bÃ i rao cáº§n embedding: {len(df)}")

# === 3ï¸âƒ£ Chuáº©n bá»‹ dá»¯ liá»‡u embedding ===
texts = df["text"].astype(str).tolist()
metadatas = [{"id": str(row["id"])} for _, row in df.iterrows()]

# === 4ï¸âƒ£ Táº¡o embedding ===
print(f"ğŸ§  Äang táº¡o embedding báº±ng model: {EMBED_MODEL}")
emb = OpenAIEmbeddings(model=EMBED_MODEL)

if BACKEND == "faiss":
    vdb = FAISS.from_texts(texts, embedding=emb, metadatas=metadatas)
    save_path = os.path.join(VDB_DIR, "text_embeddings")
    vdb.save_local(save_path)
    print(f"ğŸ’¾ ÄÃ£ lÆ°u FAISS vÃ o: {save_path}")
else:
    save_path = os.path.join(VDB_DIR, "text_embeddings_chroma")
    vdb = Chroma.from_texts(
        texts,
        embedding=emb,
        metadatas=metadatas,
        persist_directory=save_path
    )
    vdb.persist()
    print(f"ğŸ’¾ ÄÃ£ lÆ°u Chroma vÃ o: {save_path}")

print("âœ… HoÃ n táº¥t embedding text dataset!")
