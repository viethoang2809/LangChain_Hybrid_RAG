# app/utils/hybrid_helpers.py
import os
import json
from typing import List, Dict, Any
from openai import OpenAI

from app.retrievers.vector_tools import VectorClient, Passage


# ======================
# ğŸ”¹ Load rule tá»•ng há»£p cÃ¢u tráº£ lá»i
# ======================
def load_answer_rule(path: str = "app/prompts/answer_synthesis.txt") -> str:
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y rule tá»•ng há»£p cÃ¢u tráº£ lá»i: {path}")
    with open(path, "r", encoding="utf-8") as f:
        return f.read().strip()


# ======================
# ğŸ”¹ Táº¡o map ID -> Record (tá»« Neo4j)
# ======================
def build_id_map_from_graph_records(records: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
    """Táº¡o map id -> record (thuá»™c tÃ­nh tá»« Neo4j)."""
    id_map = {}
    for r in records or []:
        rid = str(r.get("id") or "").strip()
        if rid:
            id_map[rid] = r
    return id_map


# ======================
# ğŸ”¹ Fetch láº¡i bÃ i viáº¿t theo ID tá»« VectorDB
# ======================
def vector_fetch_by_ids(vclient: VectorClient, ids: List[str], limit: int = 3) -> List[Passage]:
    """Truy xuáº¥t láº¡i cÃ¡c bÃ i theo ID tá»« VectorDB."""
    vs = vclient._load_vs()
    results: List[Passage] = []
    wanted = set([str(x).strip() for x in ids if x])
    try:
        for _, doc in (vs.docstore._dict or {}).items():
            mid = (doc.metadata or {}).get("id")
            if mid and str(mid).strip() in wanted:
                results.append(
                    Passage(id=str(mid).strip(), text=doc.page_content or "", score=None, metadata=doc.metadata or {})
                )
                if len(results) >= limit:
                    break
    except Exception:
        pass
    return results


# ======================
# ğŸ”¹ Chá»n top 3 bÃ i Æ°u tiÃªn giá»¯a Graph vÃ  Vector
# ======================
def select_top3_by_priority(
    graph_ids: List[str],
    vector_passages: List[Passage],
    vclient: VectorClient,
    graph_id_map: Dict[str, Dict[str, Any]],
    fill_limit: int = 3
) -> List[Passage]:
    """Chá»n top 3 bÃ i Æ°u tiÃªn trÃ¹ng ID giá»¯a Graph vÃ  Vector."""
    picked: List[Passage] = []
    used_ids = set()
    graph_ids = [str(x).strip() for x in graph_ids if str(x).strip()]
    vector_by_id = {str(p.id).strip(): p for p in vector_passages if p.id}

    # 1ï¸âƒ£ Overlap giá»¯a Graph & Vector
    for gid in graph_ids:
        if gid in vector_by_id and gid not in used_ids:
            picked.append(vector_by_id[gid])
            used_ids.add(gid)
            if len(picked) >= fill_limit:
                return picked

    # 2ï¸âƒ£ Graph cÃ³ ID nhÆ°ng Vector chÆ°a cÃ³ â†’ fetch thá»§ cÃ´ng
    missing_from_vector = [gid for gid in graph_ids if gid not in used_ids and gid not in vector_by_id]
    if missing_from_vector:
        fetched = vector_fetch_by_ids(vclient, missing_from_vector, limit=(fill_limit - len(picked)))
        for p in fetched:
            if p.id and p.id not in used_ids:
                picked.append(p)
                used_ids.add(p.id)
                if len(picked) >= fill_limit:
                    return picked

    # 3ï¸âƒ£ Bá»• sung tá»« vector_passages cÃ²n láº¡i
    for p in vector_passages:
        pid = str(p.id).strip() if p.id else None
        if pid and pid not in used_ids:
            picked.append(p)
            used_ids.add(pid)
        if len(picked) >= fill_limit:
            break

    return picked[:fill_limit]


# ======================
# ğŸ”¹ Chuáº©n bá»‹ input tá»•ng há»£p (graph + vector)
# ======================
def build_synthesis_input(chosen_passages: List[Passage], graph_id_map: Dict[str, Dict[str, Any]]) -> str:
    """Táº¡o text cÃ³ cáº¥u trÃºc Ä‘á»ƒ gá»­i LLM tá»•ng há»£p."""
    blocks = []
    for p in chosen_passages:
        pid = str(p.id).strip() if p.id else None
        graph_info = graph_id_map.get(pid) if pid else None
        block = {
            "id": pid or "N/A",
            "graph": graph_info or {},
            "vector_text": (p.text or "").strip(),
        }
        blocks.append(block)

    pretty = []
    for b in blocks:
        pretty.append(
            f"ID: {b['id']}\nGRAPH: {json.dumps(b['graph'], ensure_ascii=False)}\nTEXT: {b['vector_text']}"
        )
    return "\n\n---\n\n".join(pretty)


# ======================
# ğŸ”¹ Tá»•ng há»£p Ä‘áº§u ra cuá»‘i cÃ¹ng báº±ng LLM
# ======================
def llm_summarize_answer(
    client: OpenAI,
    user_query: str,
    synthesis_rule: str,
    synthesis_payload: str,
    model: str,
) -> str:
    """Gá»i LLM Ä‘á»ƒ tá»•ng há»£p cÃ¢u tráº£ lá»i."""
    prompt = f"""{synthesis_rule}

Dá»¯ liá»‡u Ä‘áº§u vÃ o:
{synthesis_payload}

CÃ¢u há»i ngÆ°á»i dÃ¹ng:
{user_query}
"""
    resp = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4,
    )
    return resp.choices[0].message.content.strip()
