import os
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS


class NL2CypherRetriever:
    """
    NL2Cypher Retriever:
    - So s√°nh semantic gi·ªØa user query v√† c√°c m·∫´u 'Question' trong CSV.
    - L·∫•y 'Cypher' t∆∞∆°ng ·ª©ng l√†m v√≠ d·ª• few-shot.
    - Gh√©p v·ªõi schema/rule t·ª´ file prompt ƒë·ªÉ sinh full prompt g·ª≠i GPT.
    """

    def __init__(
        self,
        csv_path="data/Cypher_template.csv",
        schema_path="app/prompts/nl2cypher_vi.txt",
        store_dir=".vector_store/nl2cypher_index",
        embed_model="text-embedding-3-small",
    ):
        load_dotenv()
        self.csv_path = csv_path
        self.schema_path = schema_path
        self.store_dir = store_dir
        self.embed_model = embed_model
        self.embeddings = OpenAIEmbeddings(model=self.embed_model)
        self.vdb = None

        os.makedirs(self.store_dir, exist_ok=True)
        self.schema_text = self._load_schema()
        self._load_or_build_index()

    # ======================
    # üîπ LOAD SCHEMA PROMPT
    # ======================
    def _load_schema(self):
        if not os.path.exists(self.schema_path):
            raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y file schema: {self.schema_path}")
        with open(self.schema_path, "r", encoding="utf-8") as f:
            schema_text = f.read().strip()
        print(f"üìú ƒê√£ load schema t·ª´ {self.schema_path}")
        return schema_text

    # ======================
    # üîπ LOAD / BUILD INDEX
    # ======================
    def _load_or_build_index(self):
        faiss_path = os.path.join(self.store_dir, "index.faiss")
        if os.path.exists(faiss_path):
            print("üì¶ ƒêang load FAISS index c√≥ s·∫µn...")
            self.vdb = FAISS.load_local(
                folder_path=self.store_dir,
                embeddings=self.embeddings,
                allow_dangerous_deserialization=True,
            )
        else:
            print("üöÄ Ch∆∞a c√≥ index ‚Äî ƒëang t·∫°o m·ªõi t·ª´ CSV...")
            self._build_index()

    def _build_index(self):
        df = pd.read_csv(self.csv_path)
        if not {"Question", "Cypher"}.issubset(df.columns):
            raise ValueError("‚ùå CSV ph·∫£i c√≥ 2 c·ªôt: 'Question' v√† 'Cypher'")

        texts = df["Question"].astype(str).tolist()
        metadatas = [{"Cypher": row["Cypher"]} for _, row in df.iterrows()]

        self.vdb = FAISS.from_texts(texts, embedding=self.embeddings, metadatas=metadatas)
        self.vdb.save_local(self.store_dir)
        print(f"‚úÖ ƒê√£ t·∫°o FAISS index t·ª´ {len(df)} v√≠ d·ª•.")

    # ======================
    # üîπ TRUY XU·∫§T V√ç D·ª§
    # ======================
    def retrieve_examples(self, query: str, k: int = 3):
        """T√¨m top-k v√≠ d·ª• semantic g·∫ßn nh·∫•t trong index"""
        if not self.vdb:
            raise RuntimeError("‚ö†Ô∏è VectorDB ch∆∞a ƒë∆∞·ª£c load ho·∫∑c build.")
        results = self.vdb.similarity_search(query, k=k)
        return [{"Question": r.page_content, "Cypher": r.metadata["Cypher"]} for r in results]

    def debug_retrieve(self, query: str, k: int = 3):
        """In ra v√≠ d·ª• g·∫ßn nghƒ©a nh·∫•t ƒë·ªÉ debug"""
        examples = self.retrieve_examples(query, k)
        print(f"\nüîç Top-{k} v√≠ d·ª• semantic g·∫ßn nh·∫•t cho: '{query}'\n")
        for i, ex in enumerate(examples, 1):
            print(f"--- V√≠ d·ª• {i} ---")
            print("‚ùì Question:", ex["Question"])
            print("üí¨ Cypher:", ex["Cypher"])
            print()

    # ======================
    # üîπ T·∫†O PROMPT CHO GPT
    # ======================
    def build_prompt(self, user_query: str, k: int = 3):
        """Gh√©p prompt ho√†n ch·ªânh ƒë·ªÉ g·ª≠i GPT"""
        examples = self.retrieve_examples(user_query, k=k)
        few_shot_text = "\n\n".join(
            [
                f"(V√≠ d·ª• {i+1})\n"
                f"H·ªèi (ng·ªØ nghƒ©a t∆∞∆°ng t·ª±): {ex['Question']}\n"
                f"Truy v·∫•n Cypher t∆∞∆°ng ·ª©ng:\n{ex['Cypher']}"
                for i, ex in enumerate(examples)
            ]
        )

        prompt = f"""
{self.schema_text}

D∆∞·ªõi ƒë√¢y l√† m·ªôt v√†i v√≠ d·ª• t∆∞∆°ng t·ª± (retrieved b·∫±ng semantic search):
{few_shot_text}

C√¢u h·ªèi ng∆∞·ªùi d√πng:
{user_query}

Ch·ªâ tr·∫£ v·ªÅ DUY NH·∫§T code block ch·ª©a truy v·∫•n Cypher h·ª£p l·ªá.
"""
        return prompt


# ======================
# üîπ DEMO
# ======================
if __name__ == "__main__":
    retriever = NL2CypherRetriever()
    query = "T√¨m nh√† s·ªï ƒë·ªè ch√≠nh ch·ªß t·∫°i Thanh Xu√¢n"
    retriever.debug_retrieve(query)
    print("\nüß† PROMPT G·ª¨I GPT:\n")
    print(retriever.build_prompt(query, k=3))
