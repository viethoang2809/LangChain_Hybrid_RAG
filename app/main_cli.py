# app/main_cli.py
import os, sys, json, traceback, argparse
from dotenv import load_dotenv
from openai import OpenAI

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from app.retrievers.hybrid_retriever import HybridRetriever
from app.retrievers.vector_tools import VectorClient
from app.utils.hybrid_helpers import (
    load_answer_rule,
    build_id_map_from_graph_records,
    select_top3_by_priority,
    build_synthesis_input,
    llm_summarize_answer,
)

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
client = OpenAI(api_key=OPENAI_API_KEY)


def run_query_once(user_query: str, top_k: int = 10, limit: int = 3, show_debug: bool = False):
    """Cháº¡y má»™t truy váº¥n Hybrid RAG duy nháº¥t."""
    print(f"\nâ“ {user_query}\n")

    synth_rule = load_answer_rule()
    hybrid = HybridRetriever()
    vclient = hybrid.vector

    print("â³ Äang truy váº¥n dá»¯ liá»‡u tá»« Neo4j vÃ  FAISS...\n")
    hybrid_result = hybrid.search(user_query=user_query, top_k=top_k)
    graph_records = hybrid_result["graph_records"]
    graph_ids = hybrid_result["graph_ids"]
    vector_passages = hybrid_result["vector_passages"]

    graph_id_map = build_id_map_from_graph_records(graph_records)
    chosen_passages = select_top3_by_priority(graph_ids, vector_passages, vclient, graph_id_map, fill_limit=limit)

    if show_debug:
        print("ğŸ“Š Graph IDs:", graph_ids)
        print("ğŸ“š Vector IDs:", [p.id for p in vector_passages])
        print("âœ… Chosen IDs:", [p.id for p in chosen_passages])
        print()

    synthesis_payload = build_synthesis_input(chosen_passages, graph_id_map)
    print("ğŸ§  Äang tá»•ng há»£p cÃ¢u tráº£ lá»i...\n")
    answer = llm_summarize_answer(client, user_query, synth_rule, synthesis_payload, OPENAI_MODEL)

    print("âœ¨ CÃ‚U TRáº¢ Lá»œI:\n------------------------------------------------")
    print(answer)
    print("------------------------------------------------")

    # Hiá»ƒn thá»‹ snippet ngáº¯n
    print("\nğŸ“‹ Dá»® LIá»†U Há»¢P NHáº¤T:")
    for p in chosen_passages:
        pid = str(p.id).strip() if p.id else "N/A"
        snippet = (p.text or "").strip()[:120].replace("\n", " ")
        print(f"â€¢ ID {pid}: {snippet}...")


def main():
    parser = argparse.ArgumentParser(description="Hybrid RAG CLI cho Báº¥t Ä‘á»™ng sáº£n HÃ  Ná»™i")
    parser.add_argument("--query", type=str, help="CÃ¢u há»i ngÆ°á»i dÃ¹ng (náº¿u khÃ´ng cÃ³, sáº½ báº­t cháº¿ Ä‘á»™ nháº­p tay)")
    parser.add_argument("--k", type=int, default=10, help="Sá»‘ lÆ°á»£ng top-k káº¿t quáº£ vector")
    parser.add_argument("--limit", type=int, default=3, help="Giá»›i háº¡n sá»‘ cÄƒn Ä‘á»ƒ tá»•ng há»£p")
    parser.add_argument("--show-debug", action="store_true", help="Hiá»ƒn thá»‹ debug IDs")
    args = parser.parse_args()

    print("ğŸ  Hybrid RAG â€“ Báº¥t Ä‘á»™ng sáº£n HÃ  Ná»™i (CLI mode)")
    print("================================================")

    try:
        # Náº¿u cÃ³ query -> cháº¡y má»™t láº§n rá»“i thoÃ¡t
        if args.query:
            run_query_once(args.query, args.k, args.limit, args.show_debug)
            return

        # KhÃ´ng cÃ³ query -> báº­t cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c
        print("ğŸ—¨ï¸  Nháº­p cÃ¢u há»i cá»§a báº¡n (gÃµ 'exit' Ä‘á»ƒ thoÃ¡t):\n")
        while True:
            user_query = input("â“> ").strip()
            if not user_query:
                continue
            if user_query.lower() in ["exit", "quit", "q"]:
                print("ğŸ‘‹ Táº¡m biá»‡t!")
                break
            run_query_once(user_query, args.k, args.limit, args.show_debug)

    except KeyboardInterrupt:
        print("\nğŸ›‘ Dá»«ng chÆ°Æ¡ng trÃ¬nh.")
    except Exception as e:
        print("âŒ Lá»—i khi xá»­ lÃ½ truy váº¥n:", e)
        print(traceback.format_exc())


if __name__ == "__main__":
    main()
